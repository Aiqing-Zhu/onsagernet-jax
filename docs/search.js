window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "onsagernet", "modulename": "onsagernet", "kind": "module", "doc": "<h1 id=\"onsagernet-package\">OnsagerNet package</h1>\n\n<p>This package implements the basic routines for building and training\n(with or without model reduction/closure modelling)\nOnsagerNet and variants.</p>\n\n<h2 id=\"main-modules\">Main Modules</h2>\n\n<ul>\n<li><code>onsagernet.dynamics</code>: Dynamic models, including SDEs, OnsagerNet, and variants</li>\n<li><code>onsagernet.transformations</code>: Transformations for dimensionality reduction and reconstruction</li>\n<li><code>onsagernet.trainers</code>: Training routines for SDEs and those with dimensionality transformations</li>\n<li><code>onsagernet.models</code>: Basic model definitions (mostly fully connected neural networks) that are used in references [1-3]</li>\n</ul>\n\n<h2 id=\"references\">References</h2>\n\n<ol>\n<li>Chen, X. et al. Constructing custom thermodynamics using deep learning. Nature Computational Science 4, 66-85 (2024).</li>\n<li>Novoselov, K. S. &amp; Li, Q. Learning physical laws from observations of complex dynamics. Nature Computational Science 1-2 (2024).</li>\n<li>Yu, H., Tian, X., E, W. &amp; Li, Q. OnsagerNet: Learning stable and interpretable dynamics using a generalized Onsager principle. Phys. Rev. Fluids 6, 114402 (2021).</li>\n</ol>\n"}, {"fullname": "onsagernet.dynamics", "modulename": "onsagernet.dynamics", "kind": "module", "doc": "<h1 id=\"dynamical-models\">Dynamical models</h1>\n\n<p>This module defines the dynamical models used in the OnsagerNet and related architectures.\nNote that the actual model components' architectures are not defined here, but rather it is the\nassembly logic for the model components that is handled here.</p>\n\n<p>The following is an example of how to use the <code>OnsagerNet</code> model\nto create the stochastic OnsagerNet dynamics</p>\n\n<p>$$\n    dX(t) = -\n    \\left[\n        M(X(t)) + W(x(t))\n    \\right] \\nabla V(x(t), u(t)) dt\n    + \\sqrt{\\epsilon} \\sigma(x(t), u(t)) dW(t)\n    \\qquad\n    X(t) \\in \\mathbb{R}^d, \\quad u(t) \\in \\mathbb{R}^m.\n$$</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"kn\">import</span> <span class=\"nn\">equinox</span> <span class=\"k\">as</span> <span class=\"nn\">eqx</span>\n<span class=\"kn\">from</span> <span class=\"nn\">onsagernet.dynamics</span> <span class=\"kn\">import</span> <span class=\"n\">OnsagerNet</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyPotential</span><span class=\"p\">(</span><span class=\"n\">eqx</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Implement your V function here</span>\n\n<span class=\"sd\">    This should be a function (d + m) -&gt; (1)</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyDissipation</span><span class=\"p\">(</span><span class=\"n\">eqx</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Implement your M function here</span>\n\n<span class=\"sd\">    This should be a function (d) -&gt; (d, d)</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyConservation</span><span class=\"p\">(</span><span class=\"n\">eqx</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Implement your W function here</span>\n\n<span class=\"sd\">    This should be a function (d) -&gt; (d, d)</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyDiffusion</span><span class=\"p\">(</span><span class=\"n\">eqx</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Implement your sigma function here</span>\n\n<span class=\"sd\">    This should be a function (d + m) -&gt; (d, d)</span>\n<span class=\"sd\">    &quot;&quot;&quot;</span>\n\n\n<span class=\"n\">potential</span> <span class=\"o\">=</span> <span class=\"n\">MyPotential</span><span class=\"p\">()</span>\n<span class=\"n\">dissipation</span> <span class=\"o\">=</span> <span class=\"n\">MyDissipation</span><span class=\"p\">()</span>\n<span class=\"n\">conservation</span> <span class=\"o\">=</span> <span class=\"n\">MyConservation</span><span class=\"p\">()</span>\n<span class=\"n\">diffusion</span> <span class=\"o\">=</span> <span class=\"n\">MyDiffusion</span><span class=\"p\">()</span>\n\n<span class=\"n\">sde</span> <span class=\"o\">=</span> <span class=\"n\">OnsagerNet</span><span class=\"p\">(</span>\n    <span class=\"n\">potential</span><span class=\"o\">=</span><span class=\"n\">potential</span><span class=\"p\">,</span>\n    <span class=\"n\">dissipation</span><span class=\"o\">=</span><span class=\"n\">dissipation</span><span class=\"p\">,</span>\n    <span class=\"n\">conservation</span><span class=\"o\">=</span><span class=\"n\">conservation</span><span class=\"p\">,</span>\n    <span class=\"n\">diffusion</span><span class=\"o\">=</span><span class=\"n\">diffusion</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</code></pre>\n</div>\n\n<p>The <code>sde</code> instance can then be used to simulate the dynamics\nof the system or perform training.</p>\n\n<ul>\n<li>Some simple definition of the potential, dissipation, conservation, and diffusion functions are\nprovided in <code>onsagernet.models</code></li>\n<li>The <code>ReducedSDE</code> class includes both an <code>SDE</code> component and a dimensionality reduction component\ninvolving both an <code>onsagernet.transformations.Encoder</code> and a <code>onsagernet.transformations.Decoder</code></li>\n<li>Standard training routines are provided in <code>onsagernet.trainers</code></li>\n</ul>\n"}, {"fullname": "onsagernet.dynamics.DynamicCallable", "modulename": "onsagernet.dynamics", "qualname": "DynamicCallable", "kind": "variable", "doc": "<p></p>\n", "default_value": "typing.Callable[[typing.Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex], typing.Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex], typing.Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex]], jax.Array]"}, {"fullname": "onsagernet.dynamics.SDE", "modulename": "onsagernet.dynamics", "qualname": "SDE", "kind": "class", "doc": "<p>Base class for stochastic differential equations models.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.dynamics.SDE.drift", "modulename": "onsagernet.dynamics", "qualname": "SDE.drift", "kind": "function", "doc": "<p>Drift function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: drift vector field</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.SDE.diffusion", "modulename": "onsagernet.dynamics", "qualname": "SDE.diffusion", "kind": "function", "doc": "<p>Diffusion function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: diffusion matrix of size (state_dim, bm_dim)</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.SDEfromFunc", "modulename": "onsagernet.dynamics", "qualname": "SDEfromFunc", "kind": "class", "doc": "<p>SDE model defined by providing drift and diffusion functions.</p>\n", "bases": "SDE"}, {"fullname": "onsagernet.dynamics.SDEfromFunc.__init__", "modulename": "onsagernet.dynamics", "qualname": "SDEfromFunc.__init__", "kind": "function", "doc": "<p>SDE model defined by providing drift and diffusion functions.</p>\n\n<p>This implements the dynamics\n$$\n    dX(t) = f(t, X(t), u(t)) dt + g(t, X(t), u(t)) dW(t)\n$$\nwhere $f$ is the drift function and $g$ is the diffusion function.\nThe <code>args</code> argument (which represents $u(t)$)\nis used to pass additional parameters to the drift and diffusion functions.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>drift_func (Callable[[ArrayLike, ArrayLike, ArrayLike], Array]):</strong>  provided drift function</li>\n<li><strong>diffusion_func (Callable[[ArrayLike, ArrayLike, ArrayLike], Array]):</strong>  provided diffusion function</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">drift_func</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">],</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">],</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]],</span> <span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">diffusion_func</span><span class=\"p\">:</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">],</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">],</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]],</span> <span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "onsagernet.dynamics.SDEfromFunc.drift", "modulename": "onsagernet.dynamics", "qualname": "SDEfromFunc.drift", "kind": "function", "doc": "<p>Drift function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: drift vector field</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.SDEfromFunc.diffusion", "modulename": "onsagernet.dynamics", "qualname": "SDEfromFunc.diffusion", "kind": "function", "doc": "<p>Diffusion function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  addional arguments or parameters</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: diffusion matrix</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.ReducedSDE", "modulename": "onsagernet.dynamics", "qualname": "ReducedSDE", "kind": "class", "doc": "<p>SDE model with encoder and decoder with dimensionality reduction or closure modelling.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.dynamics.ReducedSDE.__init__", "modulename": "onsagernet.dynamics", "qualname": "ReducedSDE.__init__", "kind": "function", "doc": "<p>SDE model with encoder and decoder with dimensionality reduction or closure modelling.</p>\n\n<p>The <code>sde</code> attribute can be any model of the <a href=\"#SDE\">SDE</a> class or its sub-classes.\nThe <code>encoder</code> must be a (sub-)class of <code>onsagernet.transformations.Encoder</code> and\nthe <code>decoder</code> must be a (sub-)class of <code>onsagernet.transformations.Decoder</code>.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>encoder (Encoder):</strong>  The encoder function mapping the microscopic state to the reduced state</li>\n<li><strong>decoder (Decoder):</strong>  The decoder function mapping the reduced state to the microscopic state</li>\n<li><strong>sde (SDE):</strong>  The stochastic dynamics for the reduced state</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">encoder</span><span class=\"p\">:</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">transformations</span><span class=\"o\">.</span><span class=\"n\">Encoder</span>,</span><span class=\"param\">\t<span class=\"n\">decoder</span><span class=\"p\">:</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">transformations</span><span class=\"o\">.</span><span class=\"n\">Decoder</span>,</span><span class=\"param\">\t<span class=\"n\">sde</span><span class=\"p\">:</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span></span>)</span>"}, {"fullname": "onsagernet.dynamics.ReducedSDE.encoder", "modulename": "onsagernet.dynamics", "qualname": "ReducedSDE.encoder", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet.transformations.Encoder"}, {"fullname": "onsagernet.dynamics.ReducedSDE.decoder", "modulename": "onsagernet.dynamics", "qualname": "ReducedSDE.decoder", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet.transformations.Decoder"}, {"fullname": "onsagernet.dynamics.ReducedSDE.sde", "modulename": "onsagernet.dynamics", "qualname": "ReducedSDE.sde", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet.dynamics.SDE"}, {"fullname": "onsagernet.dynamics.OnsagerNet", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet", "kind": "class", "doc": "<p></p>\n", "bases": "SDE"}, {"fullname": "onsagernet.dynamics.OnsagerNet.__init__", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.__init__", "kind": "function", "doc": "<p>Stochastic OnsagerNet model.</p>\n\n<p>Let $X(t) \\in \\mathbb{R}^d$. The Stochastic OnsagerNet model is defined by the SDE\n$$\n    dX(t) = -\n    \\left[\n        M(X(t)) + W(x(t))\n    \\right] \\nabla V(x(t), u(t)) dt\n    + \\sqrt{\\epsilon} \\sigma(x(t), u(t)) dW(t)\n$$\nwhere</p>\n\n<ul>\n<li>$M : \\mathbb{R}^{d} \\to \\mathbb{R}^{d\\times d}$ is the dissipation matrix, which is symmetric positive semi-definite for all $x$</li>\n<li>$W : \\mathbb{R}^{d} \\to \\mathbb{R}^{d\\times d}$ is the conservation matrix, which is anti-symmetric for all $x$</li>\n<li>$V : \\mathbb{R}^{d} \\to \\mathbb{R}$ is the potential function</li>\n<li>$\\sigma: \\mathbb{R}^{d} \\to \\mathbb{R}^{d\\times d}$ is the (square) diffusion matrix</li>\n<li>$u(t)$ are the additional parameters for the potential and diffusion functions, and note that <strong>the first dimension of $u(t)$ is the temperature $\\epsilon$</strong></li>\n</ul>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>potential (eqx.Module):</strong>  potential function $V$</li>\n<li><strong>dissipation (eqx.Module):</strong>  dissipation matrix $M$</li>\n<li><strong>conservation (eqx.Module):</strong>  conservation matrix $W$</li>\n<li><strong>diffusion (eqx.Module):</strong>  diffusion matrix $\\sigma$</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">potential</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">dissipation</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">conservation</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">diffusion</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "onsagernet.dynamics.OnsagerNet.potential", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.potential", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.dynamics.OnsagerNet.dissipation", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.dissipation", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.dynamics.OnsagerNet.conservation", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.conservation", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.dynamics.OnsagerNet.diffusion_func", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.diffusion_func", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.dynamics.OnsagerNet.drift", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.drift", "kind": "function", "doc": "<p>Drift function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters, the first element is the temperature</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: drift vector field</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.OnsagerNet.diffusion", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNet.diffusion", "kind": "function", "doc": "<p>Diffusion function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters, the first element is the temperature</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: diffusion matrix</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD", "kind": "class", "doc": "<p></p>\n", "bases": "OnsagerNet"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.__init__", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.__init__", "kind": "function", "doc": "<p>Stochastic OnsagerNet model satisfying a fluctuation-dissipation relation.</p>\n\n<p>This is a modified version of the Stochastic OnsagerNet model.\nLet $X(t) \\in \\mathbb{R}^d$. This model is defined by the SDE\n$$\n    dX(t) = -\n    \\left[\n        M(X(t)) + W(x(t))\n    \\right] \\nabla V(x(t), u(t)) dt\n    + \\sqrt{2 \\epsilon} [M(x(t)]^\\frac{1}{2}dW(t)\n$$\nwhere</p>\n\n<ul>\n<li>$M : \\mathbb{R}^{d} \\to \\mathbb{R}^{d\\times d}$ is the dissipation matrix,\nwhich is symmetric positive semi-definite for all $x$</li>\n<li>$W : \\mathbb{R}^{d} \\to \\mathbb{R}^{d\\times d}$ is the conservation matrix,\nwhich is anti-symmetric for all $x$</li>\n<li>$V : \\mathbb{R}^{d} \\to \\mathbb{R}$ is the potential function</li>\n<li>$u(t)$ are the additional parameters for the potential and diffusion functions,\nand note that <strong>the first dimension of $u(t)$ is the temperature $\\epsilon$</strong></li>\n</ul>\n\n<p>Notice that the main difference with <code>OnsagerNet</code> is that the\ndiffusion matrix is now given by a (positive semi-definite) square root of the dissipation matrix.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>potential (eqx.Module):</strong>  potential function $V$</li>\n<li><strong>dissipation (eqx.Module):</strong>  dissipation matrix $M$</li>\n<li><strong>conservation (eqx.Module):</strong>  conservation matrix $W$</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">potential</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">dissipation</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">conservation</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.shared", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.shared", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox.nn._shared.Shared"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.potential", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.potential", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.conservation", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.conservation", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.diffusion_func", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.diffusion_func", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.dissipation", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.dissipation", "kind": "variable", "doc": "<p>Dissipation matrix wrapper</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>eqx.Module: dissipation matrix module</p>\n</blockquote>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.drift", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.drift", "kind": "function", "doc": "<p>Drift function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters, the first element is the temperature</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: drift vector field</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.dynamics.OnsagerNetFD.diffusion", "modulename": "onsagernet.dynamics", "qualname": "OnsagerNetFD.diffusion", "kind": "function", "doc": "<p>Diffusion function</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters, the first element is the temperature</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: diffusion matrix</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.models", "modulename": "onsagernet.models", "kind": "module", "doc": "<h1 id=\"custom-equinox-modules-for-onsagernet-components\">Custom equinox modules for OnsagerNet components</h1>\n\n<p>This module contains custom equinox modules for the components of the OnsagerNet model,\nwhich are used in various examples provided in the repository.</p>\n\n<p>For new applications, it is suggested to try the simple models here first\nand then build upon them, adapting if necessary to the specific problem at hand.</p>\n"}, {"fullname": "onsagernet.models.MLP", "modulename": "onsagernet.models", "qualname": "MLP", "kind": "class", "doc": "<p>Multi-layer perceptron.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.models.MLP.__init__", "modulename": "onsagernet.models", "qualname": "MLP.__init__", "kind": "function", "doc": "<p>Multi-layer perceptron.</p>\n\n<p>Example:\n<code>mlp = MLP(key=jax.random.PRNGKey(0), dim=2, units=[32, 32, 1], activation='tanh')</code>\ngives a 2-hidden-layer MLP</p>\n\n<p>$$2 \\to 32 \\to 32 \\to 1$$</p>\n\n<p>with tanh activation.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>, </span><span class=\"param\"><span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span>)</span>"}, {"fullname": "onsagernet.models.MLP.layers", "modulename": "onsagernet.models", "qualname": "MLP.layers", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[equinox.nn._linear.Linear]"}, {"fullname": "onsagernet.models.MLP.activation", "modulename": "onsagernet.models", "qualname": "MLP.activation", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Callable[[Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex]], jax.Array]"}, {"fullname": "onsagernet.models.PotentialMLP", "modulename": "onsagernet.models", "qualname": "PotentialMLP", "kind": "class", "doc": "<p>Potential network based on a multi-layer perceptron.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.PotentialMLP.__init__", "modulename": "onsagernet.models", "qualname": "PotentialMLP.__init__", "kind": "function", "doc": "<p>Potential network based on a multi-layer perceptron.</p>\n\n<p>This implements the potential function\n$$\n    V(x, args) = \\alpha \\|(x, args)\\|^2 + \\text{MLP}(x, args)\n$$\nwhere $x$ is the input and $u$ are additional parameters.\nThe constant $\\alpha \\geq 0$ is a regularisation term,\nwhich gives a quadratic growth to ensure that the potential is integrable.\nWe are tacitly assuming that MLP is of sub-quadratic growth,\nso only choose activation functions that have this property\n(most activation functions are either bounded or of linear growth).</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n<li><strong>param_dim (int, optional):</strong>  dimensions of the parameters. Defaults to 0.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">param_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "onsagernet.models.PotentialMLP.alpha", "modulename": "onsagernet.models", "qualname": "PotentialMLP.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.PotentialMLP.dim", "modulename": "onsagernet.models", "qualname": "PotentialMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.PotentialMLP.param_dim", "modulename": "onsagernet.models", "qualname": "PotentialMLP.param_dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.PotentialResMLP", "modulename": "onsagernet.models", "qualname": "PotentialResMLP", "kind": "class", "doc": "<p>Potential network with a residual connection.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.PotentialResMLP.__init__", "modulename": "onsagernet.models", "qualname": "PotentialResMLP.__init__", "kind": "function", "doc": "<p>Potential network with a residual connection.</p>\n\n<p>This implements the modified potential function\n$$\n    V(x, args) = \\alpha \\|(x, args)\\|^2\n    + \\frac{1}{2}\n    \\| \\text{MLP}(x, args)+ \\Gamma (x, args) \\|^2\n$$\nwhere</p>\n\n<ul>\n<li>$\\phi$ is a MLP of dim + param_dim -> n_pot</li>\n<li>$\\Gamma$ ia matrix of size [n_pot, dim + para_dim]</li>\n<li>$\\alpha &gt; 0$ is a scalar regulariser</li>\n</ul>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>n_pot (int):</strong>  size of the MLP part of the potential</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n<li><strong>param_dim (int, optional):</strong>  dimension of the parameters. Defaults to 0.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">n_pot</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">param_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "onsagernet.models.PotentialResMLP.alpha", "modulename": "onsagernet.models", "qualname": "PotentialResMLP.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.PotentialResMLP.gamma_layer", "modulename": "onsagernet.models", "qualname": "PotentialResMLP.gamma_layer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox.nn._linear.Linear"}, {"fullname": "onsagernet.models.PotentialResMLP.dim", "modulename": "onsagernet.models", "qualname": "PotentialResMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.PotentialResMLP.param_dim", "modulename": "onsagernet.models", "qualname": "PotentialResMLP.param_dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DissipationMatrixMLP", "modulename": "onsagernet.models", "qualname": "DissipationMatrixMLP", "kind": "class", "doc": "<p>Dissipation matrix network based on a multi-layer perceptron.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.DissipationMatrixMLP.__init__", "modulename": "onsagernet.models", "qualname": "DissipationMatrixMLP.__init__", "kind": "function", "doc": "<p>Dissipation matrix network based on a multi-layer perceptron.</p>\n\n<p>The MLP maps $x$ of dimension <code>dim</code> to a matrix $L(x)$ of size <code>dim</code> x <code>dim</code>,\nand then reshapes it to a <code>dim</code> x <code>dim</code> matrix.\nThen, the output matrix is given by\n$$\n    M(x) = \\alpha I + L(x) L(x)^\\top.\n$$\nIf <code>is_bounded</code> is set to <code>True</code>, then the output is element-wise bounded\nby applying a <code>jax.nn.tanh</code> activation to the output matrix $L$.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n<li><strong>is_bounded (bool, optional):</strong>  whether to give a element-wise bounded output. Defaults to True.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">is_bounded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "onsagernet.models.DissipationMatrixMLP.alpha", "modulename": "onsagernet.models", "qualname": "DissipationMatrixMLP.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.DissipationMatrixMLP.is_bounded", "modulename": "onsagernet.models", "qualname": "DissipationMatrixMLP.is_bounded", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "onsagernet.models.DissipationMatrixMLP.dim", "modulename": "onsagernet.models", "qualname": "DissipationMatrixMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.ConservationMatrixMLP", "modulename": "onsagernet.models", "qualname": "ConservationMatrixMLP", "kind": "class", "doc": "<p>Conservation matrix network based on a multi-layer perceptron.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.ConservationMatrixMLP.__init__", "modulename": "onsagernet.models", "qualname": "ConservationMatrixMLP.__init__", "kind": "function", "doc": "<p>Conservation matrix network based on a multi-layer perceptron.</p>\n\n<p>The MLP maps $x$ of dimension <code>dim</code> to a matrix $L(x)$ of size <code>dim</code> x <code>dim</code>,\nand then reshapes it to a <code>dim</code> x <code>dim</code> matrix.\nThen, the output matrix is given by\n$$\n    W(x) = L(x) - L(x)^\\top.\n$$\nIf <code>is_bounded</code> is set to <code>True</code>, then the output is element-wise bounded\nby applying a <code>jax.nn.tanh</code> activation to the output matrix $L$.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>is_bounded (bool, optional):</strong>  whether to give a element-wise bounded output. Defaults to True.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">is_bounded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span>)</span>"}, {"fullname": "onsagernet.models.ConservationMatrixMLP.is_bounded", "modulename": "onsagernet.models", "qualname": "ConservationMatrixMLP.is_bounded", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "onsagernet.models.ConservationMatrixMLP.dim", "modulename": "onsagernet.models", "qualname": "ConservationMatrixMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DiffusionMLP", "modulename": "onsagernet.models", "qualname": "DiffusionMLP", "kind": "class", "doc": "<p>Diffusion matrix network based on a multi-layer perceptron.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.DiffusionMLP.__init__", "modulename": "onsagernet.models", "qualname": "DiffusionMLP.__init__", "kind": "function", "doc": "<p>Diffusion matrix network based on a multi-layer perceptron.</p>\n\n<p>This implements the diffusion matrix function\n$$\n    \\sigma(x, args) = \\text{Chol}(\\alpha I + \\text{MLP}(x, args))\n$$\nwhere $\\text{Chol}$ is the Cholesky decomposition.\nHere, MLP maps $(x, args)$ of dimension <code>dim</code> + <code>param_dim</code> to a matrix of size <code>dim</code> x <code>dim</code>,</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n<li><strong>param_dim (int, optional):</strong>  dimension of the parameters. Defaults to 0.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">param_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "onsagernet.models.DiffusionMLP.alpha", "modulename": "onsagernet.models", "qualname": "DiffusionMLP.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.DiffusionMLP.dim", "modulename": "onsagernet.models", "qualname": "DiffusionMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DiffusionMLP.param_dim", "modulename": "onsagernet.models", "qualname": "DiffusionMLP.param_dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DiffusionDiagonalMLP", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalMLP", "kind": "class", "doc": "<p>Diagonal diffusion matrix network based on a multi-layer perceptron.</p>\n", "bases": "MLP"}, {"fullname": "onsagernet.models.DiffusionDiagonalMLP.__init__", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalMLP.__init__", "kind": "function", "doc": "<p>Diagonal diffusion matrix network based on a multi-layer perceptron.</p>\n\n<p>This implements the diffusion matrix function\n$$\n    \\sigma(x, args) = \\text{diag}(\\alpha + \\text{MLP}(x, args)^2)^{\\frac{1}{2}}.\n$$\nHere, MLP maps $(x, args)$ of dimension <code>dim</code> + <code>param_dim</code> to a vector of size <code>dim</code>.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>units (list[int]):</strong>  layer sizes</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n<li><strong>param_dim (int, optional):</strong>  dimension of the parameters. Defaults to 0.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">param_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span>)</span>"}, {"fullname": "onsagernet.models.DiffusionDiagonalMLP.alpha", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalMLP.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.DiffusionDiagonalMLP.dim", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalMLP.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DiffusionDiagonalMLP.param_dim", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalMLP.param_dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.DiffusionDiagonalConstant", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalConstant", "kind": "class", "doc": "<p>Diagonal diffusion matrix network based on a constant layer.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.models.DiffusionDiagonalConstant.__init__", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalConstant.__init__", "kind": "function", "doc": "<p>Diagonal diffusion matrix network based on a constant layer.</p>\n\n<p>This implements the diffusion matrix function that is constant\n$$\n    \\sigma(x, args) = \\text{diag}(\\alpha + \\text{Constant}^2)^{\\frac{1}{2}}.\n$$\nwhere $\\text{Constant}$ is a vector of size <code>dim</code>.\nNote that by constant we mean that it does not depend on the input $x$ or the parameters $args$,\nbut it can be trained.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>dim (int):</strong>  dimension of the input</li>\n<li><strong>alpha (float):</strong>  regulariser</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>, </span><span class=\"param\"><span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "onsagernet.models.DiffusionDiagonalConstant.alpha", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalConstant.alpha", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.DiffusionDiagonalConstant.constant_layer", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalConstant.constant_layer", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet._layers.ConstantLayer"}, {"fullname": "onsagernet.models.DiffusionDiagonalConstant.dim", "modulename": "onsagernet.models", "qualname": "DiffusionDiagonalConstant.dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.models.PCATransform", "modulename": "onsagernet.models", "qualname": "PCATransform", "kind": "class", "doc": "<p>PCA transform.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.models.PCATransform.__init__", "modulename": "onsagernet.models", "qualname": "PCATransform.__init__", "kind": "function", "doc": "<p>PCA transform.</p>\n\n<p>Transforms the input vector $x$ via\n$$\n    x \\mapsto \\text{components} ( x ) / \\sqrt{\\text{scaling}}.\n$$\nIf <code>centre</code> is set to <code>True</code>, then the input is first centered by subtracting the <code>mean</code>.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>mean (ArrayLike):</strong>  mean of the data used to fit the PCA</li>\n<li><strong>components (ArrayLike):</strong>  PCA components</li>\n<li><strong>scaling (ArrayLike):</strong>  scaling of the PCA transform (e.g. explained variance)</li>\n<li><strong>centre (bool, optional):</strong>  whether to center the data using <code>mean</code>. Defaults to False.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">mean</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">components</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">scaling</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">centre</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "onsagernet.models.PCATransform.mean", "modulename": "onsagernet.models", "qualname": "PCATransform.mean", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex]"}, {"fullname": "onsagernet.models.PCATransform.components", "modulename": "onsagernet.models", "qualname": "PCATransform.components", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex]"}, {"fullname": "onsagernet.models.PCATransform.scaling", "modulename": "onsagernet.models", "qualname": "PCATransform.scaling", "kind": "variable", "doc": "<p></p>\n", "annotation": ": Union[jax.Array, numpy.ndarray, numpy.bool, numpy.number, bool, int, float, complex]"}, {"fullname": "onsagernet.models.PCATransform.centre", "modulename": "onsagernet.models", "qualname": "PCATransform.centre", "kind": "variable", "doc": "<p></p>\n", "annotation": ": bool"}, {"fullname": "onsagernet.models.InversePCATransform", "modulename": "onsagernet.models", "qualname": "InversePCATransform", "kind": "class", "doc": "<p>Inverse PCA transform.</p>\n", "bases": "PCATransform"}, {"fullname": "onsagernet.models.InversePCATransform.__init__", "modulename": "onsagernet.models", "qualname": "InversePCATransform.__init__", "kind": "function", "doc": "<p>Inverse PCA transform.</p>\n\n<p>Transforms the input vector $z$ via\n$$\n    z \\mapsto \\text{components}^\\top ( z \\sqrt{\\text{scaling}} )\n$$\nIf <code>centre</code> is set to <code>True</code>, <code>mean</code> is added to the output.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>mean (ArrayLike):</strong>  mean of the data used to fit the PCA</li>\n<li><strong>components (ArrayLike):</strong>  PCA components</li>\n<li><strong>scaling (ArrayLike):</strong>  scaling of the PCA transform (e.g. explained variance)</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">mean</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">components</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">scaling</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "onsagernet.models.PCAResNetTransform", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform", "kind": "class", "doc": "<p></p>\n", "bases": "PCATransform"}, {"fullname": "onsagernet.models.PCAResNetTransform.__init__", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform.__init__", "kind": "function", "doc": "<p>PCA-ResNet transform.</p>\n\n<p>This combines the PCA transform with an MLP to give a ResNet-like architecture.\n$$\n    x \\mapsto \\text{PCA}(x) + \\text{mlp_scale} \\times \\text{MLP}(\\text{mlp_input_scale} \\times x).\n$$\nThe input scale adjusts the input (often not order 1) so that the MLP can learn the correct scale.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>mean (ArrayLike):</strong>  mean of the data used to fit the PCA</li>\n<li><strong>components (ArrayLike):</strong>  PCA components</li>\n<li><strong>scaling (ArrayLike):</strong>  scaling of the PCA transform (e.g. explained variance)</li>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>units (list[int]):</strong>  layer sizes of the MLP</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>mlp_scale (float):</strong>  scale of the MLP output</li>\n<li><strong>mlp_input_scale (float):</strong>  scale of the input to the MLP</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">mean</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">components</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">scaling</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">mlp_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">mlp_input_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "onsagernet.models.PCAResNetTransform.mlp", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform.mlp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet.models.MLP"}, {"fullname": "onsagernet.models.PCAResNetTransform.mlp_scale", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform.mlp_scale", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.PCAResNetTransform.mlp_input_scale", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform.mlp_input_scale", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.PCAResNetTransform.pca_transform", "modulename": "onsagernet.models", "qualname": "PCAResNetTransform.pca_transform", "kind": "function", "doc": "<p>Perform the PCA transform.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x (ArrayLike):</strong>  state</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: pca features</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.models.InversePCAResNetTransform", "modulename": "onsagernet.models", "qualname": "InversePCAResNetTransform", "kind": "class", "doc": "<p>Inverse PCA-ResNet transform.</p>\n", "bases": "InversePCATransform"}, {"fullname": "onsagernet.models.InversePCAResNetTransform.__init__", "modulename": "onsagernet.models", "qualname": "InversePCAResNetTransform.__init__", "kind": "function", "doc": "<p>Inverse PCA-ResNet transform.</p>\n\n<p>This combines the inverse PCA transform with an MLP to give a ResNet-like architecture.\n$$\n    z \\mapsto \\text{PCA}^{-1}(z) + \\text{mlp_scale} \\times \\text{MLP}(z).\n$$</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>mean (ArrayLike):</strong>  mean of the data used to fit the PCA</li>\n<li><strong>components (ArrayLike):</strong>  PCA components</li>\n<li><strong>scaling (ArrayLike):</strong>  scaling of the PCA transform (e.g. explained variance)</li>\n<li><strong>key (PRNGKey):</strong>  random key</li>\n<li><strong>units (list[int]):</strong>  layer sizes of the MLP</li>\n<li><strong>activation (str):</strong>  activation function (can be any in <code>jax.nn</code> or custom ones defined in <code>onsagernet._activations</code>)</li>\n<li><strong>mlp_scale (float):</strong>  scale of the MLP output</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">mean</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">components</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">scaling</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">function</span> <span class=\"n\">PRNGKey</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">units</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">activation</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">mlp_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span>)</span>"}, {"fullname": "onsagernet.models.InversePCAResNetTransform.mlp", "modulename": "onsagernet.models", "qualname": "InversePCAResNetTransform.mlp", "kind": "variable", "doc": "<p></p>\n", "annotation": ": onsagernet.models.MLP"}, {"fullname": "onsagernet.models.InversePCAResNetTransform.mlp_scale", "modulename": "onsagernet.models", "qualname": "InversePCAResNetTransform.mlp_scale", "kind": "variable", "doc": "<p></p>\n", "annotation": ": float"}, {"fullname": "onsagernet.models.InversePCAResNetTransform.inverse_pca_transform", "modulename": "onsagernet.models", "qualname": "InversePCAResNetTransform.inverse_pca_transform", "kind": "function", "doc": "<p>Inverse PCA transform.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>z (ArrayLike):</strong>  reduced state</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>Array: reconstructed state</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">unknown</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.trainers", "modulename": "onsagernet.trainers", "kind": "module", "doc": "<h1 id=\"basic-trainers-for-sde-models\">Basic trainers for SDE models</h1>\n\n<p>This module implements basic training routines for SDE models.\nThe base class is <code>SDETrainer</code>, which provides the base training logic.\nThe sub-classes are required to implement the <code>SDETrainer.loss_func</code> that is used to train the model.</p>\n\n<h2 id=\"training-routines\">Training routines</h2>\n\n<p>We provide here two training routines.</p>\n\n<ul>\n<li><code>MLETrainer</code>: this implements the maximum likelihood loss <a href=\"./_losses.html#MLELoss\"><code>MLELoss</code></a>\nto estimate SDE drift and diffusion\nthrough computing the <a href=\"https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\">maximum-likelihood</a> following the\n<a href=\"https://en.wikipedia.org/wiki/Euler\u2013Maruyama_method\">Euler-Maruyama discretisation</a> of the SDE.</li>\n<li><code>ClosureMLETrainer</code>: this combines <a href=\"./_losses.html#MLELoss\"><code>MLELoss</code></a> with additional losses to enforce closure,\nnamely a reconstruction loss <a href=\"./_losses.html#ReconLoss\"><code>ReconLoss</code></a> and a\ncomparison loss <a href=\"./_losses.html#CompareLoss\"><code>CompareLoss</code></a>.\nThis follows the implementation of [1].</li>\n</ul>\n\n<p>The following example shows how to train an <code>onsagernet.dynamics.OnsagerNet</code> model using the <code>MLETrainer</code>.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"kn\">from</span> <span class=\"nn\">onsagernet.dynamics</span> <span class=\"kn\">import</span> <span class=\"n\">OnsagerNet</span>\n<span class=\"kn\">from</span> <span class=\"nn\">onsagernet.trainers</span> <span class=\"kn\">import</span> <span class=\"n\">MLETrainer</span>\n\n<span class=\"n\">sde</span> <span class=\"o\">=</span> <span class=\"n\">OnsagerNet</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">load_data</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>  <span class=\"c1\"># return a datasets.Dataset object</span>\n\n<span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">MLETrainer</span><span class=\"p\">(</span><span class=\"n\">opt_options</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">opt</span><span class=\"p\">,</span> <span class=\"n\">rop_options</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">rop</span><span class=\"p\">)</span>\n<span class=\"n\">sde</span><span class=\"p\">,</span> <span class=\"n\">losses</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span>  <span class=\"c1\"># trains the model `sde` for 10 epochs with batch size 2</span>\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">sde</span><span class=\"p\">,</span>\n    <span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"n\">dataset</span><span class=\"p\">,</span>\n    <span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>  <span class=\"c1\"># batch size should be typically small since this yields [n_batch, n_steps, n_dim] data</span>\n<span class=\"p\">)</span>\n</code></pre>\n</div>\n\n<h2 id=\"dataset-format\">Dataset format</h2>\n\n<p>The dataset is assumed\nto be a huggingface <a href=\"https://huggingface.co/docs/datasets/en/index\"><code>datasets.Dataset</code></a>\nobject with three columns: <code>t</code>, <code>x</code>, and <code>args</code>.\nHere, <code>t</code> is time, <code>x</code> is state, and <code>args</code> are additional arguments.\nLet <code>n_examples</code> be the number of examples, <code>n_dim</code> be the dimension of the state x,\n<code>n_args</code> be the dimension of the arguments, and <code>n_steps</code> be the number of time steps.\nThen, the shapes of the data entries are as follows:</p>\n\n<ul>\n<li>t: (<code>n_examples</code>, <code>n_steps</code>, <code>1</code>) - this is the sequence of time steps sampled in the time series,\nwhich can vary from one example to another (but the <code>n_steps</code> must be the same), so consider padding\nif this were not the case</li>\n<li>x: (<code>n_examples</code>, <code>n_steps</code>, <code>n_dim</code>) - this is the corresponding sequence of states</li>\n<li>args: (<code>n_examples</code>, <code>n_steps</code>, <code>n_args</code>) - this is the sequence of additional arguments,\nwhich can be constant or varying in time. If constant, you must broad-cast the values\nalong the time dimension so that the expected shapes are maintained.</li>\n</ul>\n\n<p>We also assume that <code>n_args</code> &gt;= <code>1</code>, with the first dimension always being\ntemperature, since it is relevant for all SDE models in physical modelling.\nYour custom <code>loss_func</code> routine must return a scalar loss value.</p>\n\n<p><em>In fact, it is not strictly necessary to use a <a href=\"https://huggingface.co/docs/datasets/en/index\"><code>datasets.Dataset</code></a>\nobject, but any object that can yield the correct data format by calling <code>dataset.iter(batch_size)</code>.</em></p>\n\n<h2 id=\"writing-custom-training-routines\">Writing custom training routines</h2>\n\n<p>You can write custom training routines (with custom losses, for example)\nby sub-classing <code>SDETrainer</code>.\nSub-classes must implement the <code>SDETrainer.loss_func</code> method.</p>\n\n<p>Given a model partitioned by <code>eqx.partition(model, ...)</code>,\ninto a trainable part <code>diff_model</code> and a static part <code>static_model</code>,\nthe <code>SDETrainer.loss_func</code> routine computes the loss of the model on the given dataset.\nWe always assume that the batch data is a tuple of <code>(t, x, args)</code>.</p>\n\n<p>See above for more on the format of the dataset and\n<code>MLETrainer.loss_func</code>, or the more complex <code>ClosureMLETrainer.loss_func</code> for examples.</p>\n\n<h2 id=\"references\">References</h2>\n\n<ol>\n<li>Chen, X. et al. <em>Constructing custom thermodynamics using deep learning</em>. Nature Computational Science <strong>4</strong>, 66\u201385 (2024).</li>\n</ol>\n"}, {"fullname": "onsagernet.trainers.DynamicModel", "modulename": "onsagernet.trainers", "qualname": "DynamicModel", "kind": "variable", "doc": "<p></p>\n", "default_value": "typing.Union[onsagernet.dynamics.SDE, onsagernet.dynamics.ReducedSDE]"}, {"fullname": "onsagernet.trainers.SDETrainer", "modulename": "onsagernet.trainers", "qualname": "SDETrainer", "kind": "class", "doc": "<p>Base class for training SDE models.</p>\n", "bases": "abc.ABC"}, {"fullname": "onsagernet.trainers.SDETrainer.__init__", "modulename": "onsagernet.trainers", "qualname": "SDETrainer.__init__", "kind": "function", "doc": "<p>SDE training routine.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>opt_options (dict):</strong>  dictionary of options for the optimiser</li>\n<li><strong>rop_options (dict):</strong>  dictionary of options for the reduce-on-plateau callback</li>\n<li><strong>loss_options (Optional[dict], optional):</strong>  dictionary of options for loss computation. Defaults to None.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">opt_options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">rop_options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">loss_options</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "onsagernet.trainers.SDETrainer.loss_func", "modulename": "onsagernet.trainers", "qualname": "SDETrainer.loss_func", "kind": "function", "doc": "<p>Loss function.</p>\n\n<p>This must be implemented by sub-classes.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>diff_model (DynamicModel):</strong>  the trainable part of the model</li>\n<li><strong>static_model (DynamicModel):</strong>  the static part of the model</li>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters. The first dimension is temperature.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>float: loss value</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">diff_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">static_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">t</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">args</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.trainers.SDETrainer.train", "modulename": "onsagernet.trainers", "qualname": "SDETrainer.train", "kind": "function", "doc": "<p>The main training routine.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model (DynamicModel):</strong>  the model to be trained</li>\n<li><strong>dataset (Dataset):</strong>  the dataset</li>\n<li><strong>num_epochs (int):</strong>  number of epochs to train</li>\n<li><strong>batch_size (int):</strong>  the batch size</li>\n<li><strong>logger (Optional[Logger], optional):</strong>  the logging object. Defaults to None.</li>\n<li><strong>opt_state (Optional[OptState], optional):</strong>  the starting optimiser state. Defaults to None.</li>\n<li><strong>filter_spec (Optional[Any], optional):</strong>  the filtering logic. Defaults to None.</li>\n<li><strong>checkpoint_dir (Optional[str], optional):</strong>  the directory to save checkpoints. Defaults to None.</li>\n<li><strong>checkpoint_every (Optional[int], optional):</strong>  checkpoints are saved every <code>checkpoint_every</code> number of epochs. Defaults to None.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple[DynamicModel, list[float], OptState]: trained model, list of losses, optimiser state</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">arrow_dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span>,</span><span class=\"param\">\t<span class=\"n\">num_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">logger</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Logger</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">opt_state</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)],</span> <span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)]]],</span> <span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)],</span> <span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)]]],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">filter_spec</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"n\">Any</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">checkpoint_dir</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">checkpoint_every</span><span class=\"p\">:</span> <span class=\"n\">Optional</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">],</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">],</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)],</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)]]],</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Iterable</span><span class=\"p\">[</span><span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)],</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Mapping</span><span class=\"p\">[</span><span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">ForwardRef</span><span class=\"p\">(</span><span class=\"s1\">&#39;ArrayTree&#39;</span><span class=\"p\">)]]]]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.trainers.MLETrainer", "modulename": "onsagernet.trainers", "qualname": "MLETrainer", "kind": "class", "doc": "<p>Base class for training SDE models.</p>\n", "bases": "SDETrainer"}, {"fullname": "onsagernet.trainers.MLETrainer.loss_func", "modulename": "onsagernet.trainers", "qualname": "MLETrainer.loss_func", "kind": "function", "doc": "<p>The MLE loss function.</p>\n\n<p>See <a href=\"./_losses.html#MLELoss\"><code>MLELoss</code></a> for more details.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>diff_model (DynamicModel):</strong>  the trainable part of the model</li>\n<li><strong>static_model (DynamicModel):</strong>  the static part of the model</li>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>float: the computed loss</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">diff_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">static_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">t</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">args</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.trainers.ClosureMLETrainer", "modulename": "onsagernet.trainers", "qualname": "ClosureMLETrainer", "kind": "class", "doc": "<p>Base class for training SDE models.</p>\n", "bases": "MLETrainer"}, {"fullname": "onsagernet.trainers.ClosureMLETrainer.loss_func", "modulename": "onsagernet.trainers", "qualname": "ClosureMLETrainer.loss_func", "kind": "function", "doc": "<p>The combined loss function for MLE training with closure modelling.</p>\n\n<p>The losses are applied to the combine model\n<code>model = eqx.combine(diff_model, static_model)</code>\nwith three parts</p>\n\n<ul>\n<li><a href=\"./_losses.html#MLELoss\"><code>MLELoss</code></a> applied to <code>model.sde</code></li>\n<li><a href=\"./_losses.html#ReconLoss\"><code>ReconLoss</code></a> applied to the <code>model</code></li>\n<li><a href=\"./_losses.html#CompareLoss\"><code>CompareLoss</code></a> applied to the <code>model</code></li>\n</ul>\n\n<p>The combined loss is given by\n$$\n    \\text{loss} = \\text{loss_sde}\n    + \\text{recon_weight} \\times \\text{loss_recon}\n    + \\text{compare_weight} \\times \\text{loss_compare}\n$$</p>\n\n<p>The variables <code>recon_weight</code> and <code>compare_weight</code> are set\nin the <code>loss_options</code> attribute.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>diff_model (DynamicModel):</strong>  the trainable part of the model</li>\n<li><strong>static_model (DynamicModel):</strong>  the static part of the model</li>\n<li><strong>t (ArrayLike):</strong>  time</li>\n<li><strong>x (ArrayLike):</strong>  state</li>\n<li><strong>args (ArrayLike):</strong>  additional arguments or parameters.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>float: the computed loss</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">diff_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">static_model</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">SDE</span><span class=\"p\">,</span> <span class=\"n\">onsagernet</span><span class=\"o\">.</span><span class=\"n\">dynamics</span><span class=\"o\">.</span><span class=\"n\">ReducedSDE</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">t</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">args</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">jax</span><span class=\"o\">.</span><span class=\"n\">Array</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">bool</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">number</span><span class=\"p\">,</span> <span class=\"nb\">bool</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"nb\">complex</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "onsagernet.transformations", "modulename": "onsagernet.transformations", "kind": "module", "doc": "<h1 id=\"dimensionality-transformations\">Dimensionality transformations</h1>\n\n<p>This module contains classes for dimensionality transformations, such as encoders and decoders.\nThese are to be used in the context where reduced dynamics is sought after,\nbut only microscopic data is available.</p>\n\n<p>The main classes are <code>Encoder</code> and <code>Decoder</code>, which are abstract classes that should be\nimplemented by the user. The <code>ClosureEncoder</code> and <code>ClosureDecoder</code> classes are concrete\nimplementations of the <code>Encoder</code> and <code>Decoder</code> classes, respectively.\nThey are used to encode and decode the data into a reduced space,\nafter which the reduced dynamics can be trained.\nIn this case the reduced space consist of both known macroscopic coordinates\nand learned closure coordinates.</p>\n\n<p>The <code>Encoder</code> and <code>Decoder</code> objects are used in <code>onsagernet.dynamics.ReducedSDE</code>\nto be used for closure modelling, for example.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"kn\">from</span> <span class=\"nn\">onsagernet.transformations</span> <span class=\"kn\">import</span> <span class=\"n\">ClosureEncoder</span><span class=\"p\">,</span> <span class=\"n\">ClosureDecoder</span>\n<span class=\"kn\">from</span> <span class=\"nn\">onsagernet.dynamics</span> <span class=\"o\">=</span> <span class=\"n\">ReducedSDE</span><span class=\"p\">,</span> <span class=\"n\">OnsagerNet</span>\n\n<span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">ClosureEncoder</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"n\">decoder</span> <span class=\"o\">=</span> <span class=\"n\">ClosureDecoder</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"n\">sde</span> <span class=\"o\">=</span> <span class=\"n\">OnsagerNet</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n\n<span class=\"n\">reduced_sde</span> <span class=\"o\">=</span> <span class=\"n\">ReducedSDE</span><span class=\"p\">(</span><span class=\"n\">encoder</span><span class=\"p\">,</span> <span class=\"n\">decoder</span><span class=\"p\">,</span> <span class=\"n\">sde</span><span class=\"p\">)</span>  <span class=\"c1\"># can be used to train, predict, etc</span>\n</code></pre>\n</div>\n\n<p>As in <code>onsagernet.dynamics</code>, only the model assembly logic is provided here.\nSome example implementations of the model architecture are provided\nin the <code>onsagernet.models</code> module.</p>\n"}, {"fullname": "onsagernet.transformations.Encoder", "modulename": "onsagernet.transformations", "qualname": "Encoder", "kind": "class", "doc": "<p>The base class for encoders.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.transformations.Decoder", "modulename": "onsagernet.transformations", "qualname": "Decoder", "kind": "class", "doc": "<p>The base class for decoders.</p>\n", "bases": "equinox._module.Module"}, {"fullname": "onsagernet.transformations.EncoderfromFunc", "modulename": "onsagernet.transformations", "qualname": "EncoderfromFunc", "kind": "class", "doc": "<p>Encoder constructed from a given closure transform.</p>\n", "bases": "Encoder"}, {"fullname": "onsagernet.transformations.EncoderfromFunc.__init__", "modulename": "onsagernet.transformations", "qualname": "EncoderfromFunc.__init__", "kind": "function", "doc": "<p>Encoder constructed from a given closure transform.</p>\n\n<p>Takes a given closure transformation $x\\mapsto z$\nto define the encoder.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>closure_transform (eqx.Module):</strong>  a given transformation $x\\mapsto z$</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">closure_transform</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "onsagernet.transformations.EncoderfromFunc.closure_transform", "modulename": "onsagernet.transformations", "qualname": "EncoderfromFunc.closure_transform", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.transformations.DecoderfromFunc", "modulename": "onsagernet.transformations", "qualname": "DecoderfromFunc", "kind": "class", "doc": "<p>Decoder constructed from a given inverse closure transform.</p>\n", "bases": "Decoder"}, {"fullname": "onsagernet.transformations.DecoderfromFunc.__init__", "modulename": "onsagernet.transformations", "qualname": "DecoderfromFunc.__init__", "kind": "function", "doc": "<p>Decoder constructed from a given inverse closure transform.</p>\n\n<p>Takes a given inverse closure transformation $z\\mapsto x$</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>inverse_closure_transform (eqx.Module):</strong>  a given transformation $z\\mapsto x$</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">inverse_closure_transform</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "onsagernet.transformations.DecoderfromFunc.inverse_closure_transform", "modulename": "onsagernet.transformations", "qualname": "DecoderfromFunc.inverse_closure_transform", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.transformations.ClosureEncoder", "modulename": "onsagernet.transformations", "qualname": "ClosureEncoder", "kind": "class", "doc": "<p>Closure encoder which combines known macroscopic coordinates\nwith learned (or PCA) closure coordinates.</p>\n", "bases": "EncoderfromFunc"}, {"fullname": "onsagernet.transformations.ClosureEncoder.__init__", "modulename": "onsagernet.transformations", "qualname": "ClosureEncoder.__init__", "kind": "function", "doc": "<p>Closure encoder which combines known macroscopic coordinates\nwith learned (or PCA) closure coordinates.</p>\n\n<p>$$\n    x \\mapsto z = [\\varphi^*(x), \\hat\\varphi(x)]\n$$</p>\n\n<p>where $\\varphi^*$ is the known macroscopic transformation and\n$\\hat\\varphi$ is the learned closure transformation.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>macroscopic_transform (eqx.Module):</strong>  the known macroscopic transformation</li>\n<li><strong>closure_transform (eqx.Module):</strong>  the learned closure transformation</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">macroscopic_transform</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">closure_transform</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "onsagernet.transformations.ClosureEncoder.macroscopic_transform", "modulename": "onsagernet.transformations", "qualname": "ClosureEncoder.macroscopic_transform", "kind": "variable", "doc": "<p></p>\n", "annotation": ": equinox._module.Module"}, {"fullname": "onsagernet.transformations.ClosureEncoder.closure_transform", "modulename": "onsagernet.transformations", "qualname": "ClosureEncoder.closure_transform", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "onsagernet.transformations.ClosureDecoder", "modulename": "onsagernet.transformations", "qualname": "ClosureDecoder", "kind": "class", "doc": "<p>Decodes from a closure encoder model output.</p>\n", "bases": "DecoderfromFunc"}, {"fullname": "onsagernet.transformations.ClosureDecoder.__init__", "modulename": "onsagernet.transformations", "qualname": "ClosureDecoder.__init__", "kind": "function", "doc": "<p>Closure decoder which extracts the closure coordinates from the reduced state\nand then applies the inverse closure transformation to reconstruct the microscopic state.</p>\n\n<p>$$\n    z[\\text{macroscopic_dim}:] \\mapsto x\n$$</p>\n\n<p>It is assuemd that the first <code>macroscopic_dim</code> coordinates are the known\nmacroscopic coordinates and the rest are the learned closure coordinates.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>inverse_closure_transform (eqx.Module):</strong>  transformation from closure coordinates to microscopic state</li>\n<li><strong>macroscopic_dim (int):</strong>  the dimension of the known macroscopic state</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">inverse_closure_transform</span><span class=\"p\">:</span> <span class=\"n\">equinox</span><span class=\"o\">.</span><span class=\"n\">_module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">macroscopic_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "onsagernet.transformations.ClosureDecoder.macroscopic_dim", "modulename": "onsagernet.transformations", "qualname": "ClosureDecoder.macroscopic_dim", "kind": "variable", "doc": "<p></p>\n", "annotation": ": int"}, {"fullname": "onsagernet.transformations.ClosureDecoder.inverse_closure_transform", "modulename": "onsagernet.transformations", "qualname": "ClosureDecoder.inverse_closure_transform", "kind": "variable", "doc": "<p></p>\n"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();